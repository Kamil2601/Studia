{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Składnia języka ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Term:\n",
    "    def __str__(self):\n",
    "        pass\n",
    "\n",
    "    def debug_str(self):\n",
    "        pass\n",
    "\n",
    "    def is_var(self):\n",
    "        return False\n",
    "\n",
    "    def is_lambda(self):\n",
    "        return False\n",
    "\n",
    "    def is_app(self):\n",
    "        return False\n",
    "\n",
    "class Var(Term):\n",
    "    def __init__(self, var):\n",
    "        self.var = var\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.var)\n",
    "\n",
    "    def is_var(self):\n",
    "        return True\n",
    "\n",
    "    def debug_str(self):\n",
    "        return f\"Var {self.var}\"\n",
    "\n",
    "\n",
    "class Lambda(Term):\n",
    "    def __init__(self, var: str, t: Term):\n",
    "        self.var = var\n",
    "        self.t = t\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"λ{self.var}. {self.t}\"\n",
    "\n",
    "    def debug_str(self):\n",
    "        return f\"Lambda {self.var}. ({self.t.debug_str()})\"\n",
    "\n",
    "    def is_lambda(self):\n",
    "        return True\n",
    "\n",
    "\n",
    "class App(Term):\n",
    "    def __init__(self, t1: Term, t2: Term):\n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "\n",
    "    def __str__(self):\n",
    "        res = \"\"\n",
    "        if self.t1.is_var():\n",
    "            res += f\"{self.t1}\"\n",
    "        else:\n",
    "            res += f\"({self.t1})\"\n",
    "\n",
    "        if self.t2.is_var():\n",
    "            res += f\" {self.t2}\"\n",
    "        else:\n",
    "            res += f\" ({self.t2})\"\n",
    "\n",
    "        return res\n",
    "\n",
    "    def debug_str(self):\n",
    "        return f\"App ({self.t1.debug_str()}), ({self.t2.debug_str()})\"\n",
    "\n",
    "    def is_app(self):\n",
    "        return True\n",
    "\n",
    "class Nat(Term):\n",
    "    def __init__(self, n):\n",
    "        self.n = int(n)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.n)\n",
    "\n",
    "class Add(Term):\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"add ({str(self.n)}) ({str(self.m)})\"\n",
    "\n",
    "class Mul(Term):\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"mul ({str(self.n)}) ({str(self.m)})\"\n",
    "\n",
    "class Sub(Term):\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"sub ({str(self.n)}) ({str(self.m)})\"\n",
    "\n",
    "class Eq(Term):\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"eq ({str(self.n)}) ({str(self.m)})\"\n",
    "\n",
    "class Tru(Term):\n",
    "    def __str__(self):\n",
    "        return \"true\"\n",
    "\n",
    "class Fls(Term):\n",
    "    def __str__(self):\n",
    "        return \"false\"\n",
    "\n",
    "class If(Term):\n",
    "    def __init__(self, cond, if_true, if_false):\n",
    "        self.cond = cond\n",
    "        self.if_true = if_true\n",
    "        self.if_false = if_false\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"if ({str(self.cond)}) then ({str(self.if_true)}) else ({str(self.if_false)})\"\n",
    "    \n",
    "\n",
    "class Fix(Term):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"fix ({self.f})\"\n",
    "\n",
    "class Pair(Term):\n",
    "    def __init__(self, first, second):\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"pair ({self.first}) ({self.second})\"\n",
    "\n",
    "class Fst(Term):\n",
    "    def __init__(self, pair):\n",
    "        self.pair = pair\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"fst ({self.pair})\"\n",
    "\n",
    "class Snd(Term):\n",
    "    def __init__(self, pair):\n",
    "        self.pair = pair\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"snd ({self.pair})\"\n",
    "\n",
    "class Nil(Term):\n",
    "    def __str__(self):\n",
    "        return f\"nil\"\n",
    "\n",
    "class Cons(Term):\n",
    "    def __init__(self, head, tail):\n",
    "        self.head = head\n",
    "        self.tail = tail\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"cons ({self.head}) ({self.tail})\"\n",
    "\n",
    "class Head(Term):\n",
    "    def __init__(self, t):\n",
    "        self.list = t\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"head ({self.list})\"\n",
    "\n",
    "class Tail(Term):\n",
    "    def __init__(self, t):\n",
    "        self.list = t\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"tail ({self.list})\"\n",
    "\n",
    "class IsNil(Term):\n",
    "    def __init__(self, t):\n",
    "        self.list = t\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"isnil ({self.list})\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_var(token):\n",
    "    return re.match(\"^[a-z]+$\", token)\n",
    "\n",
    "\n",
    "def is_nat(token):\n",
    "    return re.match(\"^\\d+$\", token)\n",
    "\n",
    "\n",
    "def is_lambda(token):\n",
    "    return re.match(\"^lambda [a-z]+[.]$\", token)\n",
    "\n",
    "\n",
    "def is_term(token):\n",
    "    return isinstance(token, Term)\n",
    "\n",
    "\n",
    "def lambda_var(token):\n",
    "    return token[7:-1]\n",
    "\n",
    "def tail(xs):\n",
    "    if len(xs) == 0:\n",
    "        return []\n",
    "    return xs[1:]\n",
    "\n",
    "def parse_brackets(tokens):\n",
    "    stack = []\n",
    "    for token in tokens:\n",
    "        if token == \")\":\n",
    "            error = True\n",
    "            for i in range(len(stack) - 1, -1, -1):\n",
    "                if stack[i] == \"(\":\n",
    "                    error = False\n",
    "                    stack = stack[:i] + [stack[i + 1 :]]\n",
    "                    break\n",
    "            if error:\n",
    "                raise Exception(\"Parse error\")\n",
    "        else:\n",
    "            stack.append(token)\n",
    "\n",
    "    if \"(\" in stack:\n",
    "        raise Exception(\"Parse error\")\n",
    "\n",
    "    def remove_brackets(xs):\n",
    "        while len(xs) == 1 and not isinstance(xs, str):\n",
    "            xs = xs[0]\n",
    "\n",
    "        if isinstance(xs, str):\n",
    "            return xs\n",
    "        return [remove_brackets(x) for x in xs]\n",
    "\n",
    "    return remove_brackets(stack)\n",
    "\n",
    "\n",
    "def parse_term(term_str: str):\n",
    "    term_str = \" \".join(term_str.split())\n",
    "\n",
    "    regex = \"lambda [a-z]+[.]|[a-z]+|\\d+|[(]|[)]\"\n",
    "\n",
    "    tokens = re.findall(regex, term_str)\n",
    "\n",
    "    tokens = parse_brackets(tokens)\n",
    "\n",
    "    term, list_tail = parse([tokens])\n",
    "\n",
    "    return term\n",
    "\n",
    "\n",
    "def parse(tokens):\n",
    "    try:\n",
    "        hd = tokens[0]\n",
    "    except:\n",
    "        raise Exception(\"Parse error\")\n",
    "    if isinstance(hd, list):\n",
    "        term, l = parse(hd)\n",
    "\n",
    "        while l != []:\n",
    "            t, l = parse(l)\n",
    "            term = App(term, t)\n",
    "\n",
    "        return term, tail(tokens)\n",
    "\n",
    "    if is_lambda(hd):\n",
    "        var = lambda_var(hd)\n",
    "        term, l = parse(tail(tokens))\n",
    "\n",
    "        while l != []:\n",
    "            t, l = parse(l)\n",
    "            term = App(term, t)\n",
    "\n",
    "        return Lambda(var, term), l\n",
    "\n",
    "    elif hd in ['add', 'mul', 'sub', 'eq', 'cons', 'pair']:\n",
    "        t1, l1 = parse(tail(tokens))\n",
    "        t2, l2 = parse(l1)\n",
    "\n",
    "        if hd == 'add':\n",
    "            return Add(t1, t2), l2\n",
    "        elif hd == 'mul':\n",
    "            return Mul(t1,t2), l2\n",
    "        elif hd == 'sub':\n",
    "            return Sub(t1,t2), l2\n",
    "        elif hd == 'eq':\n",
    "            return Eq(t1,t2), l2\n",
    "        elif hd == 'cons':\n",
    "            return Cons(t1,t2), l2\n",
    "        elif hd == 'pair':\n",
    "            return Pair(t1,t2), l2\n",
    "    \n",
    "    elif hd == \"if\":\n",
    "        t1, l1 = parse(tail(tokens))\n",
    "        t2, l2 = parse(l1)\n",
    "        t3, l3 = parse(l2)\n",
    "\n",
    "        return If(t1,t2,t3), l3\n",
    "\n",
    "    elif hd == \"true\":\n",
    "        return Tru(), tail(tokens)\n",
    "    elif hd == \"false\":\n",
    "        return Fls(), tail(tokens)\n",
    "    elif hd == \"nil\":\n",
    "        return Nil(), tail(tokens)\n",
    "\n",
    "    elif hd in [\"fst\", \"snd\", \"head\", \"tail\", \"isnil\", \"fix\"]:\n",
    "        t, l = parse(tail(tokens))\n",
    "\n",
    "        if hd == \"fst\":\n",
    "            return Fst(t), l\n",
    "        elif hd == \"snd\":\n",
    "            return Snd(t), l\n",
    "        elif hd == \"head\":\n",
    "            return Head(t), l\n",
    "        elif hd == \"tail\":\n",
    "            return Tail(t), l\n",
    "        elif hd == \"isnil\":\n",
    "            return IsNil(t), l\n",
    "        elif hd == \"fix\":\n",
    "            return Fix(t), l\n",
    "\n",
    "    elif is_var(hd):\n",
    "        return Var(hd), tail(tokens)\n",
    "    elif is_nat(hd):\n",
    "        return Nat(hd), tail(tokens)\n",
    "\n",
    "# e ::= x | λx.e | e e |\n",
    "#     n | add e e | mul e e | sub e e | eq e e | (liczby naturalne)\n",
    "#     true | false | if e e e | (warto´sci logiczne)\n",
    "#     fix e | (rekursja)\n",
    "#     pair e e | fst e | snd e | (pary)\n",
    "#     nil | cons e e | head e | tail e | isnil e (listy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odcukrzanie ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nat_to_lambda(n):\n",
    "    app = Var(\"z\")\n",
    "\n",
    "    for _ in range(n):\n",
    "        app = App(Var(\"s\"), app)\n",
    "\n",
    "    return Lambda(\"s\", (Lambda(\"z\", app)))\n",
    "\n",
    "\n",
    "def desugar(term: Term):\n",
    "    if isinstance(term, Var):\n",
    "        return term\n",
    "    elif isinstance(term, Lambda):\n",
    "        return Lambda(term.var, desugar(term.t))\n",
    "    elif isinstance(term, App):\n",
    "        return App(desugar(term.t1), desugar(term.t2))\n",
    "    elif isinstance(term, Nat):\n",
    "        return nat_to_lambda(term.n)\n",
    "    elif isinstance(term, Add):\n",
    "        add = parse_term(\"lambda m. lambda n. lambda s. lambda z. m s (n s z)\")\n",
    "        return App(App(add, desugar(term.n)), desugar(term.m))\n",
    "    elif isinstance(term, Mul):\n",
    "        plus = \"(lambda m. lambda n. lambda s. lambda z. m s (n s z))\"\n",
    "        times = parse_term(f\"lambda m. lambda n. m ({plus} n) (lambda s. lambda n. n)\")\n",
    "        return App(App (times, desugar(term.n)), desugar(term.m))\n",
    "    elif isinstance(term, Sub):\n",
    "        zz = Pair(Nat(0), Nat(0))\n",
    "        ss = Lambda(\"p\", Pair(Snd(Var(\"p\")), Add(Nat(1), Snd(Var(\"p\")))))\n",
    "        prd = Lambda(\"m\", Fst(App(App(Var(\"m\"), ss), zz)))\n",
    "        return desugar(Lambda(\"m\", Lambda(\"n\", App(App(Var(\"n\"), prd), Var(\"m\")))))\n",
    "    elif isinstance(term, Eq):\n",
    "        isZero = parse_term(\"lambda n. n (lambda x. false) true\")\n",
    "        leq = Lambda(\"m\", Lambda(\"n\", App(isZero, Sub(Var(\"m\"), Var(\"n\")))))\n",
    "        lambda_and = parse_term(\"lambda p. lambda q. p q p\")\n",
    "        m_leq_n = App(App(leq, Var(\"m\")), Var(\"n\"))\n",
    "        n_leq_m = App(App(leq, Var(\"n\")), Var(\"m\"))\n",
    "        return Lambda(\"m\", Lambda(\"n\", App(App(lambda_and, m_leq_n), n_leq_m)))\n",
    "    elif isinstance(term, Tru):\n",
    "        return Lambda(\"t\", (Lambda(\"f\", Var(\"t\"))))\n",
    "    elif isinstance(term, Fls):\n",
    "        return Lambda(\"t\", (Lambda(\"f\", Var(\"f\"))))\n",
    "    elif isinstance(term, If):\n",
    "        return App(App(desugar(term.cond), desugar(term.if_true)), desugar(term.if_false))\n",
    "    elif isinstance(term, Fix):\n",
    "        fix = parse_term(\"lambda f. (lambda x. f (lambda y. x x y)) (lambda x. f (lambda y. x x y))\")\n",
    "        return App(fix, desugar(term.f))\n",
    "    elif isinstance(term, Pair):\n",
    "        pair =  parse_term(\"lambda f. lambda s. lambda b. b f s\")\n",
    "        return App(App(pair, desugar(term.first)), desugar(term.second))\n",
    "    elif isinstance(term, Fst):\n",
    "        fst = Lambda(\"p\", App(Var(\"p\"), Lambda(\"t\", (Lambda(\"f\", Var(\"t\"))))))\n",
    "        return App(fst, desugar(term.pair))\n",
    "    elif isinstance(term, Snd):\n",
    "        snd = Lambda(\"p\", App(Var(\"p\"), Lambda(\"t\", (Lambda(\"f\", Var(\"f\"))))))\n",
    "        return App(snd, desugar(term.pair))\n",
    "    elif isinstance(term, Nil):\n",
    "        return parse_term(\"lambda c. lambda n. n\")\n",
    "    elif isinstance(term, Cons):\n",
    "        cons = parse_term(\"lambda h. lambda t. lambda c. lambda n. c h (t c n)\")\n",
    "        return App(App(cons, desugar(term.head)), desugar(term.tail))\n",
    "    elif isinstance(term, Head):\n",
    "        head = parse_term(\"lambda l. l (lambda h. lambda t. h) (lambda t. lambda f. f)\")\n",
    "        return desugar(App(head, term.list))\n",
    "    elif isinstance(term, Tail):\n",
    "        tru = \"(lambda t. lambda f. t)\"\n",
    "        fls = \"(lambda t. lambda f. f)\"\n",
    "\n",
    "        pair = \"(lambda f. lambda s. lambda b. b f s)\"\n",
    "        fst = f\"(lambda p. p {tru})\"\n",
    "        snd = f\"(lambda p. p {fls})\"\n",
    "\n",
    "        tail = parse_term(f\"lambda l. {fst} (l (lambda x. lambda p. pair ({snd} p) (cons x ({snd} p))) ({pair} nil nil))\")\n",
    "\n",
    "        return desugar(App(tail, term.list))\n",
    "\n",
    "    elif isinstance(term, IsNil):\n",
    "        tru = \"(lambda t. lambda f. t)\"\n",
    "        fls = \"(lambda t. lambda f. f)\"\n",
    "\n",
    "        isnil = parse_term(f\"lambda l. l (lambda h. lambda t. {fls}) {tru}\")\n",
    "        return App(isnil, desugar(term.list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwersja zmienne <-> indeksy de Bruijna ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "λx. 0 z\n"
     ]
    }
   ],
   "source": [
    "def normal_to_deBruijn(term: Term):\n",
    "    free_vars = {}\n",
    "\n",
    "    def convert(t: Term, bound_vars):\n",
    "        if t.is_var():\n",
    "            try:\n",
    "                return Var(bound_vars.index(t.var))\n",
    "            except:\n",
    "                if t.var not in free_vars:\n",
    "                    free_var_index = len(free_vars)\n",
    "                    free_vars[t.var] = free_var_index\n",
    "                return Var(free_vars[t.var] + len(bound_vars))\n",
    "        elif t.is_app():\n",
    "            return App(convert(t.t1, bound_vars), convert(t.t2, bound_vars))\n",
    "        elif t.is_lambda():\n",
    "            return Lambda(t.var, convert(t.t, [t.var] + bound_vars))\n",
    "\n",
    "    return convert(term, []), list(free_vars.keys())\n",
    "\n",
    "\n",
    "def deBruijn_to_normal(term, free_vars):\n",
    "    def convert(t: Term, bound_vars):\n",
    "        if t.is_var():\n",
    "            if len(bound_vars) > t.var:\n",
    "                return Var(bound_vars[t.var])\n",
    "            else:\n",
    "                return Var(free_vars[t.var - len(bound_vars)])\n",
    "        elif t.is_app():\n",
    "            return App(convert(t.t1, bound_vars), convert(t.t2, bound_vars))\n",
    "        elif t.is_lambda():\n",
    "            return Lambda(t.var, convert(t.t, [t.var] + bound_vars))\n",
    "\n",
    "    return convert(term, [])\n",
    "\n",
    "def restore_free_vars(term, free_vars):\n",
    "    def convert(t: Term, bound_vars):\n",
    "        if t.is_var():\n",
    "            if len(bound_vars) > t.var:\n",
    "                return t\n",
    "            else:\n",
    "                return Var(free_vars[t.var - len(bound_vars)])\n",
    "        elif t.is_app():\n",
    "            return App(convert(t.t1, bound_vars), convert(t.t2, bound_vars))\n",
    "        elif t.is_lambda():\n",
    "            return Lambda(t.var, convert(t.t, [t.var] + bound_vars))\n",
    "\n",
    "    return convert(term, [])\n",
    "\n",
    "t = parse_term(\"lambda x. x z\")\n",
    "db, f = normal_to_deBruijn(t)\n",
    "print(restore_free_vars(db, f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maszyna Krivine'a (dla termów zamkniętych) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_krivine(term: Term):\n",
    "    stack = []\n",
    "    env = []\n",
    "\n",
    "    while True:\n",
    "        if term.is_app():\n",
    "            stack.append((term.t2, env))\n",
    "            term = term.t1\n",
    "\n",
    "        elif term.is_lambda():\n",
    "            if len(stack) == 0:\n",
    "                return term, env\n",
    "\n",
    "            stack_top = stack.pop()\n",
    "            env = [stack_top] + env\n",
    "            term = term.t\n",
    "\n",
    "        elif term.is_var():\n",
    "            index = term.var\n",
    "            if index >= len(env):\n",
    "                if len(stack) == 0:\n",
    "                    return term, env\n",
    "                else:\n",
    "                    raise Exception(\"Not implemented\")\n",
    "            else:\n",
    "                index = term.var\n",
    "                term, env = env[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizacja przez podstawienie ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [n -> s]t\n",
    "def substitution(t,n,s,):\n",
    "    if t.is_var():\n",
    "        if t.var == n:\n",
    "            return s\n",
    "        else:\n",
    "            return t\n",
    "    elif t.is_app():\n",
    "        return App(substitution(t.t1, n, s), substitution(t.t2, n, s))\n",
    "    elif t.is_lambda():\n",
    "        return Lambda(t.var, substitution(t.t, n + 1, s))\n",
    "\n",
    "\n",
    "def normalize_subst_cbn(t):\n",
    "    if t.is_app():\n",
    "        t1_norm = normalize_subst_cbn(t.t1)\n",
    "        if t1_norm.is_lambda():\n",
    "            beta_reduced = substitution(t1_norm.t, 0, t.t2)\n",
    "            return normalize_subst_cbn(beta_reduced)\n",
    "        return App(t1_norm, t.t2)\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "def normalize_subst_no(t):\n",
    "    t_normalized_cbn = normalize_subst_cbn(t)\n",
    "\n",
    "    if t_normalized_cbn.is_lambda():\n",
    "        return Lambda(t_normalized_cbn.var, normalize_subst_no(t_normalized_cbn.t))\n",
    "    elif t_normalized_cbn.is_app():\n",
    "        return App(\n",
    "            normalize_subst_no(t_normalized_cbn.t1),\n",
    "            normalize_subst_no(t_normalized_cbn.t2),\n",
    "        )\n",
    "\n",
    "    return t_normalized_cbn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "def alpha_equal(t1, t2):\n",
    "    if t1.is_var() and t2.is_var():\n",
    "        return t1.var == t2.var\n",
    "    elif t1.is_lambda() and t2.is_lambda():\n",
    "        return alpha_equal(t1.t, t2.t)\n",
    "    elif t1.is_app() and t2.is_app():\n",
    "        lefts_equal = alpha_equal(t1.t1, t2.t1)\n",
    "        if lefts_equal:\n",
    "            return alpha_equal(t1.t2, t2.t2)\n",
    "        return False\n",
    "\n",
    "def beta_equal(clo1, clo2):\n",
    "    t1, free1 = clo1\n",
    "    t2, free2 = clo2\n",
    "    normalized_t1 = normalize_subst_no(t1)\n",
    "    normalized_t2 = normalize_subst_no(t2)\n",
    "\n",
    "    normalized_t1_free_vars = restore_free_vars(normalized_t1, free1)\n",
    "    normalized_t2_free_vars = restore_free_vars(normalized_t2, free2)\n",
    "\n",
    "    return alpha_equal(normalized_t1_free_vars, normalized_t2_free_vars)\n",
    "\n",
    "t1 = normal_to_deBruijn(desugar(parse_term(\"y add 3 2\")))\n",
    "t2 = normal_to_deBruijn(desugar(parse_term(\"x add 1 4\")))\n",
    "\n",
    "print(beta_equal(t1, t2))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
